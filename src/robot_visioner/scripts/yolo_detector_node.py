#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import Header
from cv_bridge import CvBridge
import cv2
import numpy as np
import time

class YOLODetectorNode(Node):
    """å¢å¼ºç‰ˆYOLOæ£€æµ‹èŠ‚ç‚¹"""
    
    def __init__(self):
        super().__init__('yolo_detector')
        
        # åˆå§‹åŒ–æ—¥å¿—æ—¶é—´æˆ³
        self._last_log_time = 0
        self._last_info_time = 0
        
        # é€ä¸ªå£°æ˜å‚æ•°
        self.declare_parameter('model_path', 'yolov8n-seg.pt')
        self.declare_parameter('confidence_threshold', 0.5)
        self.declare_parameter('iou_threshold', 0.4)
        self.declare_parameter('device', 'cpu')
        
        # è¾“å…¥è¾“å‡ºè¯é¢˜
        self.declare_parameter('input_topic', '/camera/color/image_raw')
        self.declare_parameter('camera_info_topic', '/camera/color/camera_info')
        self.declare_parameter('output_detection_topic', '/yolo/detection_result')
        self.declare_parameter('output_mask_topic', '/yolo/mask')
        self.declare_parameter('output_combined_topic', '/yolo/combined_result')
        
        # åˆ†å‰²ç›¸å…³å‚æ•°
        self.declare_parameter('enable_segmentation', True)
        self.declare_parameter('mask_threshold', 0.5)
        self.declare_parameter('target_classes', '')
        self.declare_parameter('publish_individual_masks', False)
        
        # å›¾åƒå‚æ•°
        self.declare_parameter('image_width', 640)
        self.declare_parameter('image_height', 480)
        
        # æ€§èƒ½å‚æ•°
        self.declare_parameter('max_detections', 100)
        self.declare_parameter('agnostic_nms', False)
        
        # è·å–å‚æ•°å€¼
        self.load_parameters()
        
        # åˆå§‹åŒ–cv_bridge
        self.bridge = CvBridge()
        
        # å°è¯•åŠ è½½YOLOæ¨¡å‹
        self.load_model()
        
        # åˆ›å»ºè®¢é˜…è€…å’Œå‘å¸ƒè€…
        self.setup_topics()
        
        # ç›¸æœºä¿¡æ¯
        self.camera_info = None
        
        # é¢œè‰²æ˜ å°„ç”¨äºå¯è§†åŒ–
        self.colors = self.generate_colors(80)
        
        self.log_initialization_info()
    
    def throttled_log_info(self, message, throttle_sec=2.0):
        """èŠ‚æµæ—¥å¿—ä¿¡æ¯"""
        current_time = time.time()
        if current_time - self._last_info_time > throttle_sec:
            self.get_logger().info(message)
            self._last_info_time = current_time
    
    def load_parameters(self):
        """è·å–å‚æ•°å€¼"""
        self.model_path = self.get_parameter('model_path').value
        self.confidence_threshold = self.get_parameter('confidence_threshold').value
        self.iou_threshold = self.get_parameter('iou_threshold').value
        self.device = self.get_parameter('device').value
        
        self.input_topic = self.get_parameter('input_topic').value
        self.camera_info_topic = self.get_parameter('camera_info_topic').value
        self.output_detection_topic = self.get_parameter('output_detection_topic').value
        self.output_mask_topic = self.get_parameter('output_mask_topic').value
        self.output_combined_topic = self.get_parameter('output_combined_topic').value
        
        self.enable_segmentation = self.get_parameter('enable_segmentation').value
        self.mask_threshold = self.get_parameter('mask_threshold').value
        self.target_classes_str = self.get_parameter('target_classes').value
        self.publish_individual_masks = self.get_parameter('publish_individual_masks').value
        
        # è§£ætarget_classeså­—ç¬¦ä¸²
        if self.target_classes_str and self.target_classes_str.strip():
            try:
                self.target_classes = [int(x.strip()) for x in self.target_classes_str.split(',')]
            except:
                self.target_classes = []
        else:
            self.target_classes = []
        
        self.image_width = self.get_parameter('image_width').value
        self.image_height = self.get_parameter('image_height').value
        self.max_detections = self.get_parameter('max_detections').value
        self.agnostic_nms = self.get_parameter('agnostic_nms').value
    
    def load_model(self):
        """åŠ è½½YOLOæ¨¡å‹"""
        try:
            from ultralytics import YOLO
            
            self.get_logger().info(f'ğŸ¤– Loading YOLO model: {self.model_path}')
            self.model = YOLO(self.model_path)
            
            # æ£€æŸ¥è®¾å¤‡
            if self.device == 'cuda':
                try:
                    import torch
                    if torch.cuda.is_available():
                        self.model.to('cuda')
                        self.get_logger().info('âœ… Using CUDA device')
                    else:
                        self.get_logger().warn('âš ï¸ CUDA not available, using CPU')
                        self.device = 'cpu'
                except:
                    self.get_logger().warn('âš ï¸ PyTorch not available, using CPU')
                    self.device = 'cpu'
            
            self.get_logger().info(f'âœ… Model loaded successfully on device: {self.device}')
            self.get_logger().info(f'ğŸ“‹ Model classes: {self.model.names}')
            self.model_loaded = True
            
        except ImportError:
            self.get_logger().error('âŒ ultralytics not installed. Using simple fallback.')
            self.model_loaded = False
        except Exception as e:
            self.get_logger().error(f'âŒ Failed to load YOLO model: {str(e)}. Using fallback.')
            self.model_loaded = False
    
    def setup_topics(self):
        """è®¾ç½®è®¢é˜…è€…å’Œå‘å¸ƒè€…"""
        # è®¢é˜…è€…
        self.image_sub = self.create_subscription(
            Image, self.input_topic, self.image_callback, 10)
            
        self.camera_info_sub = self.create_subscription(
            CameraInfo, self.camera_info_topic, self.camera_info_callback, 10)
        
        # å‘å¸ƒè€…
        self.detection_result_pub = self.create_publisher(
            Image, self.output_detection_topic, 10)
            
        if self.enable_segmentation:
            self.mask_pub = self.create_publisher(
                Image, self.output_mask_topic, 10)
                
            self.combined_result_pub = self.create_publisher(
                Image, self.output_combined_topic, 10)
        
        self.get_logger().info(f'ğŸ“¡ Subscribed to: {self.input_topic}')
        self.get_logger().info(f'ğŸ“¤ Publishing detection to: {self.output_detection_topic}')
        if self.enable_segmentation:
            self.get_logger().info(f'ğŸ“¤ Publishing mask to: {self.output_mask_topic}')
    
    def generate_colors(self, num_classes):
        """ç”Ÿæˆç”¨äºå¯è§†åŒ–çš„éšæœºé¢œè‰²"""
        colors = []
        np.random.seed(42)
        for _ in range(num_classes):
            color = tuple(np.random.randint(50, 255, 3).tolist())
            colors.append(color)
        return colors
    
    def camera_info_callback(self, msg):
        """ç›¸æœºä¿¡æ¯å›è°ƒå‡½æ•°"""
        self.camera_info = msg
    
    def image_callback(self, msg):
        """å›¾åƒæ¶ˆæ¯å›è°ƒå‡½æ•°"""
        try:
            # è°ƒè¯•ä¿¡æ¯
            self.throttled_log_info(f'ğŸ“· Received image: {msg.width}x{msg.height}')
            
            # å°†ROSå›¾åƒæ¶ˆæ¯è½¬æ¢ä¸ºOpenCVæ ¼å¼
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            
            if self.model_loaded:
                # ä½¿ç”¨YOLOæ¨¡å‹
                results = self.model(
                    cv_image,
                    conf=self.confidence_threshold,
                    iou=self.iou_threshold,
                    max_det=self.max_detections,
                    agnostic_nms=self.agnostic_nms,
                    verbose=False
                )
                
                detection_image = self.process_detection_results(cv_image, results[0])
                
                if self.enable_segmentation:
                    combined_mask, combined_image = self.process_segmentation_results(cv_image, results[0])
                else:
                    combined_mask, combined_image = None, detection_image
            else:
                # ä½¿ç”¨ç®€å•çš„fallbackå¤„ç†
                detection_image, combined_mask, combined_image = self.simple_fallback_processing(cv_image)
            
            # å‘å¸ƒæ£€æµ‹ç»“æœ
            detection_msg = self.bridge.cv2_to_imgmsg(detection_image, "bgr8")
            detection_msg.header = msg.header
            self.detection_result_pub.publish(detection_msg)
            
            # å‘å¸ƒåˆ†å‰²ç»“æœ
            if self.enable_segmentation and combined_mask is not None:
                mask_msg = self.bridge.cv2_to_imgmsg(combined_mask, "mono8")
                mask_msg.header = msg.header
                self.mask_pub.publish(mask_msg)
                
                if combined_image is not None:
                    combined_msg = self.bridge.cv2_to_imgmsg(combined_image, "bgr8")
                    combined_msg.header = msg.header
                    self.combined_result_pub.publish(combined_msg)
            
        except Exception as e:
            self.get_logger().error(f'âŒ Error processing image: {str(e)}')
    
    def simple_fallback_processing(self, image):
        """ç®€å•çš„fallbackå¤„ç†"""
        # åˆ›å»ºåŸºäºé˜ˆå€¼çš„ç®€å•mask
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        _, mask = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)
        
        # ç¡®ä¿æœ‰ä¸€äº›maskåŒºåŸŸ
        if np.sum(mask) == 0:
            h, w = image.shape[:2]
            mask = np.zeros((h, w), dtype=np.uint8)
            cv2.rectangle(mask, (w//4, h//4), (3*w//4, 3*h//4), 255, -1)
        
        annotated = image.copy()
        cv2.putText(annotated, 'Fallback Mode', (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        mask_pixels = np.sum(mask > 0)
        self.throttled_log_info(f'ğŸ”„ Fallback: Generated mask with {mask_pixels} pixels')
        
        return annotated, mask, annotated
    
    def process_detection_results(self, image, results):
        """å¤„ç†YOLOæ£€æµ‹ç»“æœ"""
        annotated_image = image.copy()
        
        if not hasattr(results, 'boxes') or results.boxes is None:
            self.throttled_log_info('âš ï¸ No detection boxes found')
            return annotated_image
            
        boxes = results.boxes.xyxy.cpu().numpy()
        scores = results.boxes.conf.cpu().numpy()
        classes = results.boxes.cls.cpu().numpy().astype(int)
        
        self.throttled_log_info(f'ğŸ¯ Original detections: {len(boxes)} boxes, scores: {scores.min():.3f}-{scores.max():.3f}')
        
        # è¿‡æ»¤ç›®æ ‡ç±»åˆ«
        if self.target_classes:
            valid_indices = [i for i, cls in enumerate(classes) if cls in self.target_classes]
            boxes = boxes[valid_indices]
            scores = scores[valid_indices]
            classes = classes[valid_indices]
            self.throttled_log_info(f'ğŸ¯ After class filtering: {len(boxes)} boxes')
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        for i, (box, score, cls) in enumerate(zip(boxes, scores, classes)):
            x1, y1, x2, y2 = map(int, box)
            
            # è·å–ç±»åˆ«åç§°
            class_name = f'Class_{cls}'
            if hasattr(self.model, 'names'):
                class_name = self.model.names.get(cls, f'Class_{cls}')
            
            # é€‰æ‹©é¢œè‰²
            color = self.colors[cls % len(self.colors)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f'{class_name}: {score:.2f}'
            self.draw_label(annotated_image, label, (x1, y1), color)
        
        return annotated_image
    
    def process_segmentation_results(self, image, results):
        """å¤„ç†åˆ†å‰²ç»“æœ"""
        height, width = image.shape[:2]
        combined_mask = np.zeros((height, width), dtype=np.uint8)
        annotated_image = image.copy()
        
        if not hasattr(results, 'masks') or results.masks is None:
            self.throttled_log_info('âš ï¸ No segmentation masks found')
            return None, annotated_image
        
        masks = results.masks.data.cpu().numpy()
        boxes = results.boxes.xyxy.cpu().numpy() if results.boxes is not None else None
        scores = results.boxes.conf.cpu().numpy() if results.boxes is not None else None
        classes = results.boxes.cls.cpu().numpy().astype(int) if results.boxes is not None else None
        
        if classes is None:
            self.throttled_log_info('âš ï¸ No class information for masks')
            return None, annotated_image
        
        self.throttled_log_info(f'ğŸ­ Processing {len(masks)} masks')
        
        valid_mask_count = 0
        
        for i, mask in enumerate(masks):
            if i >= len(classes):
                continue
                
            cls = classes[i]
            score = scores[i] if scores is not None else 1.0
            
            # è¿‡æ»¤ç›®æ ‡ç±»åˆ«
            if self.target_classes and cls not in self.target_classes:
                continue
            
            # è·å–ç±»åˆ«åç§°
            class_name = f'Class_{cls}'
            if hasattr(self.model, 'names'):
                class_name = self.model.names.get(cls, f'Class_{cls}')
            
            # è°ƒæ•´maskå°ºå¯¸
            mask_resized = cv2.resize(mask, (width, height))
            mask_binary = (mask_resized > self.mask_threshold).astype(np.uint8) * 255
            
            # æ£€æŸ¥maskæ˜¯å¦æœ‰æ•ˆ
            mask_pixels = np.sum(mask_binary > 0)
            if mask_pixels == 0:
                continue
            
            # åˆå¹¶åˆ°æ€»maskä¸­
            combined_mask = cv2.bitwise_or(combined_mask, mask_binary)
            valid_mask_count += 1
            
            # åœ¨å¯è§†åŒ–å›¾åƒä¸Šç»˜åˆ¶mask
            color = self.colors[cls % len(self.colors)]
            colored_mask = np.zeros_like(image)
            colored_mask[mask_binary > 0] = color
            
            # å åŠ mask
            annotated_image = cv2.addWeighted(annotated_image, 0.7, colored_mask, 0.3, 0)
        
        if valid_mask_count > 0:
            total_mask_pixels = np.sum(combined_mask > 0)
            self.throttled_log_info(f'âœ… Generated final mask: {valid_mask_count} objects, {total_mask_pixels} pixels')
            return combined_mask, annotated_image
        else:
            self.throttled_log_info('âš ï¸ No valid masks generated')
            return None, annotated_image
    
    def draw_label(self, image, label, position, color):
        """ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬"""
        x, y = position
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 2
        
        # è·å–æ–‡æœ¬å°ºå¯¸
        (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, thickness)
        
        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        cv2.rectangle(image, (x, y - text_height - 10), (x + text_width, y), color, -1)
        
        # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
        cv2.putText(image, label, (x, y - 5), font, font_scale, (255, 255, 255), thickness)
    
    def log_initialization_info(self):
        """è®°å½•åˆå§‹åŒ–ä¿¡æ¯"""
        self.get_logger().info('=== YOLO Detector Node ===')
        self.get_logger().info(f'ğŸ“¦ Model: {self.model_path}')
        self.get_logger().info(f'ğŸ”§ Device: {self.device}')
        self.get_logger().info(f'âœ… Model loaded: {self.model_loaded}')
        self.get_logger().info(f'ğŸ­ Segmentation: {self.enable_segmentation}')
        self.get_logger().info(f'ğŸ¯ Confidence threshold: {self.confidence_threshold}')
        self.get_logger().info(f'ğŸ“‹ Target classes: {self.target_classes if self.target_classes else "All classes"}')

def main(args=None):
    rclpy.init(args=args)
    
    try:
        node = YOLODetectorNode()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        print(f'Error: {e}')
    finally:
        if rclpy.ok():
            rclpy.shutdown()

if __name__ == '__main__':
    main()